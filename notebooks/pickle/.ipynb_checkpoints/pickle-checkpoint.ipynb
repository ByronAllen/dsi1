{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Load and Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "import sqlalchemy\n",
    "import nltk \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = sqlalchemy.engine.create_engine('postgresql://localhost:5432/allenbyron')\n",
    "#dialect+driver://username:password@host:port/database\n",
    "\n",
    "df = pd.read_sql_table(table_name='qanda', con=engine)\n",
    "only_en_df = df[df.lang == 'en']\n",
    "df_transformed = only_en_df.drop(labels=['contributors',                 \n",
    "                                    'is_quote_status',              \n",
    "                                    'in_reply_to_status_id',        \n",
    "                                    'favorite_count',               \n",
    "                                    'source',                       \n",
    "                                    'retweeted',                    \n",
    "                                    'coordinates',                  \n",
    "                                    'entities',                     \n",
    "                                    'in_reply_to_screen_name',      \n",
    "                                    'id_str',                       \n",
    "                                    'retweet_count',                \n",
    "                                    'in_reply_to_user_id',          \n",
    "                                    'favorited',                    \n",
    "                                    'retweeted_status',             \n",
    "                                    'user_',                        \n",
    "                                    'geo',                          \n",
    "                                    'in_reply_to_user_id_str',      \n",
    "                                    'possibly_sensitive',           \n",
    "                                    'lang',                         \n",
    "                                    'created_at',                   \n",
    "                                    'filter_level',                \n",
    "                                    'in_reply_to_status_id_str', \n",
    "                                    'place',                        \n",
    "                                    'extended_entities',            \n",
    "                                    'truncated'\n",
    "                                    ],\n",
    "                            axis=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 1086)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.feature_extraction\n",
    "\n",
    "count_vec = sklearn.feature_extraction.text.CountVectorizer()\n",
    "words_array = count_vec.fit_transform(df_transformed.tweet_text)\n",
    "feature_names = count_vec.get_feature_names()\n",
    "\n",
    "words_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet\n",
    "#format: sentiwordnet.senti_synsets('word')[0].pos_score()\n",
    "\n",
    "sentiment = []\n",
    "\n",
    "for tweet in df_transformed.tweet_text:\n",
    "    \n",
    "    senti_score = 0\n",
    "    \n",
    "    for word in nltk.word_tokenize(tweet):\n",
    "        \n",
    "        try:\n",
    "            pos = sentiwordnet.senti_synsets(word)[0].pos_score()\n",
    "            senti_score += pos\n",
    "        except:\n",
    "            senti_score += 0\n",
    "        \n",
    "        try:\n",
    "            neg = sentiwordnet.senti_synsets(word)[0].neg_score()\n",
    "            senti_score -= neg\n",
    "        except:\n",
    "            senti_score += 0\n",
    "                    \n",
    "    sentiment.append(senti_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: TheilSen\n",
      "Mean Absolute Error:  1.24327631523e-15\n",
      "Coef:  [-0.04734702 -0.00703268 -0.00780995 ..., -0.00561939 -0.0214248\n",
      " -0.06918134]\n",
      "Intercept:  -0.0176719440314\n"
     ]
    }
   ],
   "source": [
    "ts = sklearn.linear_model.TheilSenRegressor()\n",
    "ts.fit(words_array.toarray(),sentiment)\n",
    "\n",
    "ts_prediction = ts.predict(words_array.toarray())\n",
    "\n",
    "print 'Type: TheilSen'\n",
    "print 'Mean Absolute Error: ', sklearn.metrics.mean_absolute_error(sentiment,ts_prediction)\n",
    "print 'Coef: ', ts.coef_\n",
    "print 'Intercept: ', ts.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "80\n",
      "160\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "(train_x,test_x,train_y,test_y) = sklearn.cross_validation.train_test_split(words_array.toarray(), sentiment, test_size=0.33)\n",
    "\n",
    "print len(train_x)\n",
    "print len(test_x)\n",
    "print len(train_y)\n",
    "print len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: TheilSen\n",
      "Mean Absolute Error:  1.24327631523e-15\n",
      "Coef:  [-0.04734702 -0.00703268 -0.00780995 ..., -0.00561939 -0.0214248\n",
      " -0.06918134]\n",
      "Intercept:  -0.0176719440314\n"
     ]
    }
   ],
   "source": [
    "ts2 = sklearn.linear_model.TheilSenRegressor()\n",
    "ts2.fit(train_x,train_y)\n",
    "\n",
    "ts2_prediction = ts2.predict(test_x)\n",
    "\n",
    "print 'Type: TheilSen'\n",
    "print 'Mean Absolute Error: ', sklearn.metrics.mean_absolute_error(sentiment,ts_prediction)\n",
    "print 'Coef: ', ts.coef_\n",
    "print 'Intercept: ', ts.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('ts.pickle', 'w')\n",
    "f.write(pickle.dumps(ts))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_x_df = pd.DataFrame(data=test_x)\n",
    "test_x_df.to_csv('test_x_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
