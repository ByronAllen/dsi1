{\rtf1\ansi\ansicpg1252\cocoartf1348\cocoasubrtf170
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\paperw11900\paperh16840\margl1440\margr1440\vieww28600\viewh15520\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f0\fs24 \cf0 \ul \ulc0 Gradient Descent\ulnone \
	moving towards the smallest derivative\
	yet you can miss lower ones depending on direction \
\
\
\ul Need to know about\ulnone \
	gradient descent \
	stochastic gradient descent\
		1. logistic regression\
		2. enormous data frames\
		3. non-simple \'97\'97\'97\'97\'97\'97\'97\'97\'97> simple relationships & how to machine learn them\
	\
	simulated annealing\
\
\ul There are some things that do not regress well\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\b \cf0 \ulnone 	Simple relationships                \

\b0 		linear\
		quadratic/cubic/polynominal\
		exponential\
		periodic\
		inverse summed with a squared \
		dozens of overlapping periods \
\

\b 	How to machine learn them\
		
\b0 RANSAC, linear, Theilsen\
		fiddle with  x1, x2, x3,\'85.\
		same with e^x or log(x)\
		former transform or try rolling averages over longer periods when std = 0\
		???\
		???\
\
	}