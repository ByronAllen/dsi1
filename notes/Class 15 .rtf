{\rtf1\ansi\ansicpg1252\cocoartf1348\cocoasubrtf170
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red38\green38\blue38;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}.}{\leveltext\leveltemplateid101\'02\'00.;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{hyphen\}}{\leveltext\leveltemplateid102\'01\uc0\u8259 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{hyphen\}}{\leveltext\leveltemplateid103\'01\uc0\u8259 ;}{\levelnumbers;}\fi-360\li2160\lin2160 }{\listname ;}\listid2}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}}
\paperw11900\paperh16840\margl1440\margr1440\vieww22640\viewh15540\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f0\b\fs40 \cf0 Class 15\
\

\b0\fs24 hypernyms: parent classification\
hyponyms: child classification\
\
sklearn.feature_extraction.text.TfidfVectorizer()\
\
	
\i a fit_transform may be used for the basis of a data frame you may need to call a get_feature_names()\

\i0 \
\pard\tx220\tx720\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\li720\fi-720\pardirnatural
\ls1\ilvl0\cf0 {\listtext	\'95	}fit()\
{\listtext	\'95	}transform()\
{\listtext	\'95	}fit_transform()\
{\listtext	\'95	}\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural
\cf0 \
Katya - Gradient Descent\
Alex - Mannwhit\
Byron - Decision function\
Gaurav - Lasso, Ridge, ElasticNet\
James - DummyRegressor / Regressor vs. Classifier\
Thamali - Standarization vs. Scaling vs. Regularization \
\
\
\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl480\sa320
\ls2\ilvl0
\fs32 \cf2 {\listtext	1.	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Research how gender guesser works. Make your own 
\b gender guesser
\b0  (perhaps using a logistic regression) and try it out on some famous novels.\
\pard\tx940\tx1440\pardeftab720\li1440\fi-1440\sl480\sa320
\ls2\ilvl1\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8259 	}Apply this against\
\pard\tx1660\tx2160\pardeftab720\li2160\fi-2160\sl480\sa320
\ls2\ilvl2\cf2 {\listtext	\uc0\u8259 	}books\
{\listtext	\uc0\u8259 	}globalgoals tweets\
{\listtext	\uc0\u8259 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \uc0\u8232 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl480\sa320
\ls2\ilvl0\cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2.	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Researchers often want to test whether a work was written by a 
\b (predict) particular author
\b0 . 
\b Lexical dispersion is one common metric,
\b0  another is the probability that they introduce a new word. Some rarer metrics are the spread of vocabulary (how often do they use the most common four hundred words), sentence length and so on. Pick one or more of these (or find some research that discusses another, and implement that) and evaluate whether these methods work.\uc0\u8232 \
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3.	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Are sad stories 100% sad, or do they start happy and have a sad ending? What out comedies? You could find out by doing 
\b sentiment analysis 
\b0 on different parts of these books.\uc0\u8232 \
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4.	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Are there any words that you mostly find in tragedies? (Or comedies, or narratives, news reports etc.) How well does this predict the kind of article?\uc0\u8232 \
}